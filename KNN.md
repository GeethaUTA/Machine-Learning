# K Nearest Neighbor- SEBASTIAN RASHAKA
* KNN Best used for Recommendation systems
## Research papers on KNN
* Automated Web usage data mining and recommendation system using KNN Classifiaction method(Recommendation sys)[https://www.sciencedirect.com/science/article/pii/S221083271400026X
* protein
## 1 Nearest Neighbor
* To train 1 NN model, we simply remember these data points
## Nearest Neighbor Decision Boundary
* The closest point depends on the distance measure. Sometimes Manhatten distance can be smaller than the eucidian distance
### Some Common Continuous Distance Measures. 
* (Distance Metrics)[https://medium.com/@kunal_gohrani/different-types-of-distance-metrics-used-in-machine-learning-e9928c5e26c7]
* Euclidian
* Manhattan
* Minkowski
* Mahalanabis
* Cosine Similarity.
### Some Discrete Distance Measures
(Distance Metrics)[https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa]
* Hamming
* Jaccard
* Dice
### Since KNN is metric dependent(DISTANCE) , Feature Scalling is very important.
## KNN in nutshell
 ![image](https://github.com/GeethaUTA/Machine-Learning/assets/144622684/19c8552a-548f-42fe-8b5b-50dd36e245af)
* Time complexity of KNN is O(n) ,n--number of training samples

  

